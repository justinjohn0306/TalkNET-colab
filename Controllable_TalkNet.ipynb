{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinjohn0306/TalkNET-colab/blob/main/Controllable_TalkNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gss5Ox_RNiba"
      },
      "source": [
        "# Controllable TalkNet\n",
        "To run TalkNet, click on Runtime -> Run all. The interface will appear at the bottom of the page when it's ready.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "*   Once the notebook is running, click on Files (the folder icon on the left edge).\n",
        "*   Upload audio clips of a singing or speaking voice by dragging and dropping them onto the sidebar.\n",
        "*   Click on \"Update file list\" in the TalkNet interface. Select an audio file from the dropdown, and type what it says into the Transcript box.\n",
        "*   Select a character, and press Generate. The first line will take a little longer to generate.\n",
        "\n",
        "## Tips and tricks\n",
        "*   If you want to use TalkNet as regular text-to-speech system, without any reference audio, tick the \"Disable reference audio\" checkbox.\n",
        "*   You can use [ARPABET](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) to override the pronunciation of words, like this: *She made a little bow, then she picked up her {B OW}.*\n",
        "*   If you're running out of memory generating lines, try to work with shorter clips.\n",
        "*   The singing models are trained on very little data, and can have a hard time pronouncing certain words. Try experimenting with ARPABET and punctuation.\n",
        "*   If the voice is off-key, the problem is usually with the extracted pitch. Press \"Debug pitch\" to listen to it. Reference audio with lots of echo/reverb or background noise, or singers with a very high vocal range can cause issues.\n",
        "*   If the singing voice sounds strained, try enabling \"Change input pitch\" and adjusting it up or down a few semitones. If you're remixing a song, remember to pitch-shift your background track as well.\n",
        "\n",
        ">Maintained by: `justinjohn0306`\n",
        "\n",
        ">Special thanks to: `Tapiocapioca#6641` and `effusiveperiscope`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqXqFgP2ri0",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 1:** Check which GPU you've been allocated.\n",
        "\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teF-Ut8Z7Gjp",
        "cellView": "form"
      },
      "source": [
        "#@markdown **Step 2:** Download dependencies.\n",
        "\n",
        "#@markdown >### Note: The runtime will crash after this cell completes, which is intended.\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "import os\n",
        "\n",
        "custom_lists = [\n",
        "    #\"https://gist.githubusercontent.com/SortAnon/997cda157954a189259c9876fd804e53/raw/example_models.json\",\n",
        "]\n",
        "\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "\n",
        "# 3.12 pytorch-lightning fix\n",
        "!pip install torchmetrics==0.11.4\n",
        "!pip install tensorflow dash==1.21.0 dash-bootstrap-components==0.13.0 jupyter-dash==0.4.0 psola wget unidecode pysptk frozendict torchvision torchaudio torchtext torch_stft kaldiio pydub pyannote.audio g2p_en pesq pystoi crepe resampy ffmpeg-python torchcrepe einops taming-transformers-rom1504==0.0.6 tensorflow-hub\n",
        "!pip uninstall gdown -y\n",
        "!pip install git+https://github.com/wkentaro/gdown.git\n",
        "!python -m pip install git+https://github.com/justinjohn0306/NeMo-py3.12\n",
        "if not os.path.exists(\"hifi-gan\"):\n",
        "    !git clone -q --recursive https://github.com/justinjohn0306/talknet-hifi-gan hifi-gan\n",
        "!git clone -q https://github.com/justinjohn0306/ControllableTalkNet\n",
        "os.chdir(\"/content/ControllableTalkNet\")\n",
        "!git archive --output=./files.tar --format=tar HEAD\n",
        "os.chdir(\"/content\")\n",
        "!tar xf ControllableTalkNet/files.tar\n",
        "!rm -rf ControllableTalkNet\n",
        "\n",
        "# 3.12 werkzeug fix\n",
        "!python -m pip install werkzeug==2.0.0 flask==2.1.2\n",
        "!pip install librosa==0.8.1\n",
        "!pip install numpy==2.1.3 numba==0.61.2\n",
        "\n",
        "os.chdir(\"/content/model_lists\")\n",
        "for c in custom_lists:\n",
        "    !wget \"{c}\"\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "\n",
        "# restart the runtime\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOXejargIPTq",
        "cellView": "form"
      },
      "source": [
        "# @markdown **Step 3:** **Start GUI**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "if not hasattr(np, \"sctypes\"):\n",
        "    np.sctypes = {\n",
        "        \"int\": [np.int8, np.int16, np.int32, np.int64],\n",
        "        \"uint\": [np.uint8, np.uint16, np.uint32, np.uint64],\n",
        "        \"float\": [np.float16, np.float32, np.float64],\n",
        "        \"complex\": [np.complex64, np.complex128],\n",
        "        \"others\": [bool, object, str, bytes],\n",
        "    }\n",
        "if not hasattr(np, \"Inf\"):\n",
        "    np.Inf = np.inf\n",
        "if not hasattr(np, \"complex\"):\n",
        "    np.complex = complex\n",
        "if not hasattr(np, \"bool\"):\n",
        "    np.bool = bool\n",
        "if not hasattr(np, \"float\"):\n",
        "    np.float = float\n",
        "\n",
        "using_inline = True\n",
        "import pkg_resources\n",
        "from pkg_resources import DistributionNotFound, VersionConflict\n",
        "\"\"\"dependencies = [\n",
        "\"tensorflow==2.4.1\",\n",
        "\"dash\",\n",
        "\"jupyter-dash\",\n",
        "\"psola\",\n",
        "\"wget\",\n",
        "\"unidecode\",\n",
        "\"pysptk\",\n",
        "\"frozendict\",\n",
        "\"torchvision==0.9.1\",\n",
        "\"torchaudio==0.8.1\",\n",
        "\"torchtext==0.9.1\",\n",
        "\"torch_stft\",\n",
        "\"kaldiio\",\n",
        "\"pydub\",\n",
        "\"pyannote.audio\",\n",
        "\"g2p_en\",\n",
        "\"pesq\",\n",
        "\"pystoi\",\n",
        "\"crepe\",\n",
        "\"resampy\",\n",
        "\"ffmpeg-python\",\n",
        "\"numpy\",\n",
        "\"scipy\",\n",
        "\"nemo_toolkit\",\n",
        "\"tqdm\",\n",
        "\"gdown\",\n",
        "]\n",
        "pkg_resources.require(dependencies)\"\"\"\n",
        "\n",
        "from controllable_talknet import *\n",
        "app.run_server(\n",
        "    mode=\"inline\",\n",
        "    #dev_tools_ui=True,\n",
        "    #dev_tools_hot_reload=True,\n",
        "    threaded=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "F4WDzfRIgb5Z"
      },
      "source": [
        "# @markdown **Step 3B:** If the above fails with a 403 error, do the following:\n",
        "# @markdown * Go to Runtime -> Restart runtime\n",
        "# @markdown * Run this cell (click the play button)\n",
        "# @markdown * Click on the googleusercontent.com link to use TalkNet in a separate tab\n",
        "import numpy as np\n",
        "\n",
        "if not hasattr(np, \"sctypes\"):\n",
        "    np.sctypes = {\n",
        "        \"int\": [np.int8, np.int16, np.int32, np.int64],\n",
        "        \"uint\": [np.uint8, np.uint16, np.uint32, np.uint64],\n",
        "        \"float\": [np.float16, np.float32, np.float64],\n",
        "        \"complex\": [np.complex64, np.complex128],\n",
        "        \"others\": [bool, object, str, bytes],\n",
        "    }\n",
        "if not hasattr(np, \"Inf\"):\n",
        "    np.Inf = np.inf\n",
        "if not hasattr(np, \"complex\"):\n",
        "    np.complex = complex\n",
        "if not hasattr(np, \"bool\"):\n",
        "    np.bool = bool\n",
        "if not hasattr(np, \"float\"):\n",
        "    np.float = float\n",
        "try:\n",
        "    using_inline\n",
        "except:\n",
        "    using_inline = False\n",
        "if not using_inline:\n",
        "    from controllable_talknet import *\n",
        "    from google.colab.output import eval_js\n",
        "\n",
        "    print(eval_js(\"google.colab.kernel.proxyPort(8050)\"))\n",
        "    app.run_server(\n",
        "        mode=\"external\",\n",
        "        debug=False,\n",
        "        #dev_tools_ui=True,\n",
        "        #dev_tools_hot_reload=True,\n",
        "        threaded=True,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}